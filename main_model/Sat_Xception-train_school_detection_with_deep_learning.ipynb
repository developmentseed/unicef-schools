{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sat-Xception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To better detect schools on a large geospatial scale, we create a deep learning python package called `Sat-Xception`. \n",
    "\n",
    "\n",
    "Sat-Xception is a deep learning python package that utilizes pre-trained models from ImageNet. The model is designed to help our partners to quickly transfer-learn and fine-tune image classification deep learning quickly with their customized images. \n",
    "\n",
    "Besides a pre-train Xception neural net, we include another light-weighted pre-trained model, called MobileNet version 2, in this python package. \n",
    "\n",
    "MobileNetV2 is a model that is slightly less accurate compared to Xception. However, it's a very light-weight, fast, and it's easy to tune for resources vs. accuracy. \n",
    "\n",
    "We have two pre-trained models in `Sat-Xception`: \n",
    "- 1) [Xception](https://arxiv.org/abs/1610.02357); \n",
    "- 2) [MobileNetV2](https://ai.googleblog.com/2018/04/mobilenetv2-next-generation-of-on.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Deep Neural Net performance and the weight](figures/DCNNs.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xception model and MobileNetV2 were released by Google in 2016 and 2018 respectively. Both models have fewer parameters (lighter weighted) compare to other existing pre-trained models (see above image) but they have achieved high accuracy with training on ImageNet. \n",
    "\n",
    "And MobileNetV2 can potentially train, transfer-learn and fine-tune client's images on mobile phones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The first iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sat_Xception installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Currently the package has only been tested on python version 3.6.3.*  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install `sat-xception` , transfer-learn and fine tune an image classification model, you need to:\n",
    "\n",
    "- set up an python environment using [conda to create a virtual environment](https://uoa-eresearch.github.io/eresearch-cookbook/recipe/2014/11/20/conda/) or use [pyenv](https://gist.github.com/Geoyi/f55ed54d24cc9ff1c14bd95fac21c042);\n",
    "\n",
    "- git clone this repo;\n",
    "- cd to main_model where the `sat-xception` is located;\n",
    "- run `pip3 install -e .` or `pip install -e .`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///example\n",
      "Collecting Cython==0.26.1 (from sat-xception==0.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/f6/3927706fef7b6a191b2274a6f74416f47d2fecb8bacd8341c634c02f7b30/Cython-0.26.1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
      "\u001b[K    100% |################################| 3.0MB 16.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting dask==0.15.3 (from sat-xception==0.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/9c/b9d211212a9012cc212d07878eee280771ba48183293639f192cde863a9d/dask-0.15.3-py2.py3-none-any.whl (527kB)\n",
      "\u001b[K    100% |################################| 532kB 39.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator==4.3.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from sat-xception==0.1.0) (4.3.0)\n",
      "Collecting distributed==1.19.1 (from sat-xception==0.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/77/2da2ebf98d633845037fef324a7c84d6b018a15fcfd0229dc6d33297c162/distributed-1.19.1-py2.py3-none-any.whl (410kB)\n",
      "\u001b[K    100% |################################| 419kB 40.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: docutils==0.14 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from sat-xception==0.1.0) (0.14)\n",
      "Requirement already satisfied: entrypoints==0.2.3 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from sat-xception==0.1.0) (0.2.3)\n",
      "Requirement already satisfied: et-xmlfile==1.0.1 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from sat-xception==0.1.0) (1.0.1)\n",
      "Collecting h5py==2.7.0 (from sat-xception==0.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/f9/a449c76cab5d310fc0f7cf56ccb7d531b8abe21dd6395312a5f9e9c330ac/h5py-2.7.0-cp36-cp36m-manylinux1_x86_64.whl (4.8MB)\n",
      "\u001b[K    100% |################################| 4.8MB 10.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting lxml==4.1.0 (from sat-xception==0.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/3e/340c17661a81656dfe96f87aa04b6ed5421673a5d2e59eb13649533f00ad/lxml-4.1.0-cp36-cp36m-manylinux1_x86_64.whl (5.6MB)\n",
      "\u001b[K    100% |################################| 5.6MB 10.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Markdown==2.6.11 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from sat-xception==0.1.0) (2.6.11)\n",
      "Requirement already satisfied: MarkupSafe==1.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from sat-xception==0.1.0) (1.0)\n",
      "Collecting matplotlib==2.1.0 (from sat-xception==0.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/9c/fcc9cfbf2454d93be66a615657cda4184954b4b67b9fc07c8511ff152b8f/matplotlib-2.1.0-cp36-cp36m-manylinux1_x86_64.whl (15.0MB)\n",
      "\u001b[K    100% |################################| 15.0MB 4.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting packaging==16.8 (from sat-xception==0.1.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/87/1b/c39b7c65b5612812b83d6cab7ef2885eac9f6beb0b7b8a7071a186aea3b1/packaging-16.8-py2.py3-none-any.whl\n",
      "Collecting pandas==0.20.3 (from sat-xception==0.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/6f/5733658857dffb998afa2120027171c263384ada0487a969e5ecd5bf9ac9/pandas-0.20.3-cp36-cp36m-manylinux1_x86_64.whl (24.5MB)\n",
      "\u001b[K    100% |################################| 24.5MB 2.7MB/s eta 0:00:01    52% |################                | 12.7MB 64.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyflakes==1.6.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from sat-xception==0.1.0) (1.6.0)\n",
      "Requirement already satisfied: Pygments==2.2.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from sat-xception==0.1.0) (2.2.0)\n",
      "Collecting pylint==1.7.4 (from sat-xception==0.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/8a/07782ece0b9db20341393f9913fb5368f9e7e4553f17c0bc91eda633f942/pylint-1.7.4-py2.py3-none-any.whl (640kB)\n",
      "\u001b[K    100% |################################| 645kB 35.9MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyOpenSSL>=17.5.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from sat-xception==0.1.0) (18.0.0)\n",
      "Collecting requests>=2.20.0 (from sat-xception==0.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\n",
      "\u001b[K    100% |################################| 61kB 31.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting rope>=0.11.0 (from sat-xception==0.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/8d/2ebe70e55742a46813952493f8fc86ff2800ccc105e2dfcb25298f7eeb72/rope-0.11.0.tar.gz (247kB)\n",
      "\u001b[K    100% |################################| 256kB 40.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting scikit-image==0.13.0 (from sat-xception==0.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/b5/bb9ade1f8c17495144f1b1e87eead3606ca7b348721a6cbac05db28d51ce/scikit_image-0.13.0-cp36-cp36m-manylinux1_x86_64.whl (34.0MB)\n",
      "\u001b[K    100% |################################| 34.0MB 2.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn==0.19.1 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from sat-xception==0.1.0) (0.19.1)\n",
      "Collecting scipy==0.19.1 (from sat-xception==0.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/46/da8d7166102d29695330f7c0b912955498542988542c0d2ae3ea0389c68d/scipy-0.19.1-cp36-cp36m-manylinux1_x86_64.whl (48.2MB)\n",
      "\u001b[K    100% |################################| 48.2MB 1.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting seaborn==0.8 (from sat-xception==0.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/13/dd3da2cd6e03e522bbd389735d3adcb47d7a4470a968ebc3348fbac8eddd/seaborn-0.8.tar.gz (178kB)\n",
      "\u001b[K    100% |################################| 184kB 40.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: simplegeneric==0.8.1 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from sat-xception==0.1.0) (0.8.1)\n",
      "Requirement already satisfied: singledispatch==3.4.0.3 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from sat-xception==0.1.0) (3.4.0.3)\n",
      "Requirement already satisfied: six==1.11.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from sat-xception==0.1.0) (1.11.0)\n",
      "Collecting tensorflow==1.10.0 (from sat-xception==0.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/e6/a6d371306c23c2b01cd2cb38909673d17ddd388d9e4b3c0f6602bfd972c8/tensorflow-1.10.0-cp36-cp36m-manylinux1_x86_64.whl (58.4MB)\n",
      "\u001b[K    100% |################################| 58.4MB 1.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tornado==4.5.2 (from sat-xception==0.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/14/52e2072197dd0e63589e875ebf5984c91a027121262aa08f71a49b958359/tornado-4.5.2.tar.gz (483kB)\n",
      "\u001b[K    100% |################################| 491kB 39.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tqdm==4.23.0 (from sat-xception==0.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/bc/de067ab2d700b91717dc5459d86a1877e2df31abfb90ab01a5a5a5ce30b4/tqdm-4.23.0-py2.py3-none-any.whl (42kB)\n",
      "\u001b[K    100% |################################| 51kB 27.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: traitlets==4.3.2 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from sat-xception==0.1.0) (4.3.2)\n",
      "Collecting typing==3.6.2 (from sat-xception==0.1.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/44/88/d09c6a7fe1af4a02f16d2f1766212bec752aadb04e5699a9706a10a1a37d/typing-3.6.2-py3-none-any.whl\n",
      "Requirement already satisfied: unicodecsv==0.14.1 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from sat-xception==0.1.0) (0.14.1)\n",
      "Collecting urllib3>=1.23 (from sat-xception==0.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/00/ee1d7de624db8ba7090d1226aebefab96a2c71cd5cfa7629d6ad3f61b79e/urllib3-1.24.1-py2.py3-none-any.whl (118kB)\n",
      "\u001b[K    100% |################################| 122kB 41.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wcwidth==0.1.7 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from sat-xception==0.1.0) (0.1.7)\n",
      "Requirement already satisfied: webencodings==0.5.1 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from sat-xception==0.1.0) (0.5.1)\n",
      "Collecting Werkzeug==0.14 (from sat-xception==0.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/9f/896df5ed2a14c9dd83eec007f8df38ab246fd27d3d2cd105f4fa0ba5ce10/Werkzeug-0.14-py2.py3-none-any.whl (322kB)\n",
      "\u001b[K    100% |################################| 327kB 34.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: widgetsnbextension>=3.1.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from sat-xception==0.1.0) (3.2.1)\n",
      "Requirement already satisfied: wrapt==1.10.11 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from sat-xception==0.1.0) (1.10.11)\n",
      "Requirement already satisfied: xlrd==1.1.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from sat-xception==0.1.0) (1.1.0)\n",
      "Collecting XlsxWriter==1.0.2 (from sat-xception==0.1.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/86/748cb5f6ef5ff2d95a7f189ef1c5124f9badc1d1293dbc214c128595e57e/XlsxWriter-1.0.2-py2.py3-none-any.whl (139kB)\n",
      "\u001b[K    100% |################################| 143kB 41.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: xlwt==1.3.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from sat-xception==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: zict==0.1.3 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from sat-xception==0.1.0) (0.1.3)\n",
      "Collecting hyperopt==0.1.1 (from sat-xception==0.1.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/ce/9f/f6324af3fc43f352e568b5850695c30ed7dd14af06a94f97953ff9187569/hyperopt-0.1.1-py3-none-any.whl\n",
      "Collecting pygeotile==1.0.6 (from sat-xception==0.1.0)\n",
      "Requirement already satisfied: tensorflow-gpu==1.10.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from sat-xception==0.1.0) (1.10.0)\n",
      "Collecting keras==2.2.4 (from sat-xception==0.1.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tblib in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from distributed==1.19.1->sat-xception==0.1.0) (1.3.2)\n",
      "Requirement already satisfied: toolz>=0.7.4 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from distributed==1.19.1->sat-xception==0.1.0) (0.9.0)\n",
      "Requirement already satisfied: sortedcontainers in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from distributed==1.19.1->sat-xception==0.1.0) (1.5.10)\n",
      "Requirement already satisfied: click>=6.6 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from distributed==1.19.1->sat-xception==0.1.0) (6.7)\n",
      "Requirement already satisfied: cloudpickle>=0.2.2 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from distributed==1.19.1->sat-xception==0.1.0) (0.5.3)\n",
      "Requirement already satisfied: msgpack-python in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from distributed==1.19.1->sat-xception==0.1.0) (0.5.6)\n",
      "Requirement already satisfied: psutil in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from distributed==1.19.1->sat-xception==0.1.0) (5.4.5)\n",
      "Requirement already satisfied: numpy>=1.7 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from h5py==2.7.0->sat-xception==0.1.0) (1.14.3)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from matplotlib==2.1.0->sat-xception==0.1.0) (2018.4)\n",
      "Requirement already satisfied: python-dateutil>=2.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from matplotlib==2.1.0->sat-xception==0.1.0) (2.7.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from matplotlib==2.1.0->sat-xception==0.1.0) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from matplotlib==2.1.0->sat-xception==0.1.0) (2.2.0)\n",
      "Requirement already satisfied: isort>=4.2.5 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from pylint==1.7.4->sat-xception==0.1.0) (4.3.4)\n",
      "Requirement already satisfied: mccabe in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from pylint==1.7.4->sat-xception==0.1.0) (0.6.1)\n",
      "Requirement already satisfied: astroid>=1.5.1 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from pylint==1.7.4->sat-xception==0.1.0) (1.6.3)\n",
      "Requirement already satisfied: cryptography>=2.2.1 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from pyOpenSSL>=17.5.0->sat-xception==0.1.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from requests>=2.20.0->sat-xception==0.1.0) (2018.4.16)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from requests>=2.20.0->sat-xception==0.1.0) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from requests>=2.20.0->sat-xception==0.1.0) (2.6)\n",
      "Requirement already satisfied: networkx>=1.8 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from scikit-image==0.13.0->sat-xception==0.1.0) (2.1)\n",
      "Requirement already satisfied: pillow>=2.1.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from scikit-image==0.13.0->sat-xception==0.1.0) (5.1.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from scikit-image==0.13.0->sat-xception==0.1.0) (0.5.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from tensorflow==1.10.0->sat-xception==0.1.0) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from tensorflow==1.10.0->sat-xception==0.1.0) (3.6.1)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from tensorflow==1.10.0->sat-xception==0.1.0) (0.4.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from tensorflow==1.10.0->sat-xception==0.1.0) (1.14.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from tensorflow==1.10.0->sat-xception==0.1.0) (0.31.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from tensorflow==1.10.0->sat-xception==0.1.0) (0.7.1)\n",
      "Requirement already satisfied: setuptools<=39.1.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from tensorflow==1.10.0->sat-xception==0.1.0) (39.1.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from tensorflow==1.10.0->sat-xception==0.1.0) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<1.11.0,>=1.10.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from tensorflow==1.10.0->sat-xception==0.1.0) (1.10.0)\n",
      "Requirement already satisfied: ipython_genutils in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from traitlets==4.3.2->sat-xception==0.1.0) (0.2.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from widgetsnbextension>=3.1.0->sat-xception==0.1.0) (5.5.0)\n",
      "Requirement already satisfied: heapdict in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from zict==0.1.3->sat-xception==0.1.0) (1.0.0)\n",
      "Collecting future (from hyperopt==0.1.1->sat-xception==0.1.0)\n",
      "Collecting pymongo (from hyperopt==0.1.1->sat-xception==0.1.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/b1/45/5440555b901a8416196fbf2499c4678ef74de8080c007104107a8cfdda20/pymongo-3.7.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from keras==2.2.4->sat-xception==0.1.0) (3.12)\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras==2.2.4->sat-xception==0.1.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/fc/94/74e0fa783d3fc07e41715973435dd051ca89c550881b3454233c39c73e69/Keras_Preprocessing-1.0.5-py2.py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.6 (from keras==2.2.4->sat-xception==0.1.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/3f/c4/2ff40221029f7098d58f8d7fb99b97e8100f3293f9856f0fb5834bef100b/Keras_Applications-1.0.6-py2.py3-none-any.whl\n",
      "Requirement already satisfied: lazy_object_proxy in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from astroid>=1.5.1->pylint==1.7.4->sat-xception==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: asn1crypto>=0.21.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from cryptography>=2.2.1->pyOpenSSL>=17.5.0->sat-xception==0.1.0) (0.24.0)\n",
      "Requirement already satisfied: cffi>=1.7 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from cryptography>=2.2.1->pyOpenSSL>=17.5.0->sat-xception==0.1.0) (1.11.5)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension>=3.1.0->sat-xception==0.1.0) (17.0.0)\n",
      "Requirement already satisfied: nbformat in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension>=3.1.0->sat-xception==0.1.0) (4.4.0)\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension>=3.1.0->sat-xception==0.1.0) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension>=3.1.0->sat-xception==0.1.0) (0.8.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension>=3.1.0->sat-xception==0.1.0) (2.10)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension>=3.1.0->sat-xception==0.1.0) (5.3.1)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension>=3.1.0->sat-xception==0.1.0) (4.8.2)\n",
      "Requirement already satisfied: jupyter-client>=5.2.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension>=3.1.0->sat-xception==0.1.0) (5.2.3)\n",
      "Requirement already satisfied: jupyter-core>=4.4.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension>=3.1.0->sat-xception==0.1.0) (4.4.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from cffi>=1.7->cryptography>=2.2.1->pyOpenSSL>=17.5.0->sat-xception==0.1.0) (2.18)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension>=3.1.0->sat-xception==0.1.0) (2.6.0)\n",
      "Requirement already satisfied: mistune>=0.7.4 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension>=3.1.0->sat-xception==0.1.0) (0.8.3)\n",
      "Requirement already satisfied: bleach in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension>=3.1.0->sat-xception==0.1.0) (2.1.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension>=3.1.0->sat-xception==0.1.0) (1.4.2)\n",
      "Requirement already satisfied: testpath in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension>=3.1.0->sat-xception==0.1.0) (0.3.1)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from ipykernel->notebook>=4.4.1->widgetsnbextension>=3.1.0->sat-xception==0.1.0) (6.4.0)\n",
      "Requirement already satisfied: html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension>=3.1.0->sat-xception==0.1.0) (1.0.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel->notebook>=4.4.1->widgetsnbextension>=3.1.0->sat-xception==0.1.0) (0.1.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel->notebook>=4.4.1->widgetsnbextension>=3.1.0->sat-xception==0.1.0) (0.12.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel->notebook>=4.4.1->widgetsnbextension>=3.1.0->sat-xception==0.1.0) (0.7.4)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.15 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel->notebook>=4.4.1->widgetsnbextension>=3.1.0->sat-xception==0.1.0) (1.0.15)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from ipython>=4.0.0->ipykernel->notebook>=4.4.1->widgetsnbextension>=3.1.0->sat-xception==0.1.0) (4.5.0)\n",
      "Requirement already satisfied: parso>=0.2.0 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from jedi>=0.10->ipython>=4.0.0->ipykernel->notebook>=4.4.1->widgetsnbextension>=3.1.0->sat-xception==0.1.0) (0.2.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/envs/jupyter_env/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0->ipykernel->notebook>=4.4.1->widgetsnbextension>=3.1.0->sat-xception==0.1.0) (0.5.2)\n",
      "Building wheels for collected packages: rope, seaborn, tornado\n",
      "  Running setup.py bdist_wheel for rope ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a6/dc/2c/962b21a00e48b50eb271500ef976af4ffd8ab45a99986b4733\n",
      "  Running setup.py bdist_wheel for seaborn ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/b7/e2/7c/d1ccdc7fb363b040901ad9414a86aa3823c5931e20bedbab46\n",
      "  Running setup.py bdist_wheel for tornado ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a5/59/09/79aad6522a5811b546e94d55c1535702dcad35880a09b03471\n",
      "Successfully built rope seaborn tornado\n",
      "Installing collected packages: Cython, dask, tornado, distributed, h5py, lxml, matplotlib, packaging, pandas, pylint, urllib3, requests, rope, scipy, scikit-image, seaborn, tensorflow, tqdm, typing, Werkzeug, XlsxWriter, future, pymongo, hyperopt, pygeotile, keras-preprocessing, keras-applications, keras, sat-xception\n",
      "  Found existing installation: Cython 0.28.2\n",
      "    Uninstalling Cython-0.28.2:\n",
      "      Successfully uninstalled Cython-0.28.2\n",
      "  Found existing installation: dask 0.17.5\n",
      "    Uninstalling dask-0.17.5:\n",
      "      Successfully uninstalled dask-0.17.5\n",
      "  Found existing installation: tornado 5.0.2\n",
      "    Uninstalling tornado-5.0.2:\n",
      "      Successfully uninstalled tornado-5.0.2\n",
      "  Found existing installation: distributed 1.21.8\n",
      "    Uninstalling distributed-1.21.8:\n",
      "      Successfully uninstalled distributed-1.21.8\n",
      "  Found existing installation: h5py 2.7.1\n",
      "    Uninstalling h5py-2.7.1:\n",
      "      Successfully uninstalled h5py-2.7.1\n",
      "  Found existing installation: lxml 4.2.1\n",
      "    Uninstalling lxml-4.2.1:\n",
      "      Successfully uninstalled lxml-4.2.1\n",
      "  Found existing installation: matplotlib 2.2.2\n",
      "    Uninstalling matplotlib-2.2.2:\n",
      "      Successfully uninstalled matplotlib-2.2.2\n",
      "  Found existing installation: packaging 17.1\n",
      "    Uninstalling packaging-17.1:\n",
      "      Successfully uninstalled packaging-17.1\n",
      "  Found existing installation: pandas 0.23.0\n",
      "    Uninstalling pandas-0.23.0:\n",
      "      Successfully uninstalled pandas-0.23.0\n",
      "  Found existing installation: pylint 1.8.4\n",
      "    Uninstalling pylint-1.8.4:\n",
      "      Successfully uninstalled pylint-1.8.4\n",
      "  Found existing installation: urllib3 1.22\n",
      "    Uninstalling urllib3-1.22:\n",
      "      Successfully uninstalled urllib3-1.22\n",
      "  Found existing installation: requests 2.18.4\n",
      "    Uninstalling requests-2.18.4:\n",
      "      Successfully uninstalled requests-2.18.4\n",
      "  Found existing installation: rope 0.10.7\n",
      "    Uninstalling rope-0.10.7:\n",
      "      Successfully uninstalled rope-0.10.7\n",
      "  Found existing installation: scipy 1.1.0\n",
      "    Uninstalling scipy-1.1.0:\n",
      "      Successfully uninstalled scipy-1.1.0\n",
      "  Found existing installation: scikit-image 0.13.1\n",
      "    Uninstalling scikit-image-0.13.1:\n",
      "      Successfully uninstalled scikit-image-0.13.1\n",
      "  Found existing installation: seaborn 0.8.1\n",
      "    Uninstalling seaborn-0.8.1:\n",
      "      Successfully uninstalled seaborn-0.8.1\n",
      "  Found existing installation: typing 3.6.4\n",
      "    Uninstalling typing-3.6.4:\n",
      "      Successfully uninstalled typing-3.6.4\n",
      "  Found existing installation: Werkzeug 0.14.1\n",
      "    Uninstalling Werkzeug-0.14.1:\n",
      "      Successfully uninstalled Werkzeug-0.14.1\n",
      "  Found existing installation: XlsxWriter 1.0.4\n",
      "    Uninstalling XlsxWriter-1.0.4:\n",
      "      Successfully uninstalled XlsxWriter-1.0.4\n",
      "  Found existing installation: Keras 2.1.5\n",
      "    Uninstalling Keras-2.1.5:\n",
      "      Successfully uninstalled Keras-2.1.5\n",
      "  Running setup.py develop for sat-xception\n",
      "Successfully installed Cython-0.26.1 Werkzeug-0.14 XlsxWriter-1.0.2 dask-0.15.3 distributed-1.19.1 future-0.17.1 h5py-2.7.0 hyperopt-0.1.1 keras-2.2.4 keras-applications-1.0.6 keras-preprocessing-1.0.5 lxml-4.1.0 matplotlib-2.1.0 packaging-16.8 pandas-0.20.3 pygeotile-1.0.6 pylint-1.7.4 pymongo-3.7.2 requests-2.21.0 rope-0.11.0 sat-xception scikit-image-0.13.0 scipy-0.19.1 seaborn-0.8 tensorflow-1.10.0 tornado-4.5.2 tqdm-4.23.0 typing-3.6.2 urllib3-1.24.1\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# under the main_model directory, install the sat-xception by\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Development Seed Data Team, a group of five expert mappers, worked on cleaning and validating school geolocations. With [clear school campus patterns in Colombia](https://paper.dropbox.com/doc/School-patterns-Colombia--ASxTzKwG7qjp7nmuI5fMTPWmAg-MaCi6NdLpkxoR8Lk4Qfrn), our expert mappers were able to confirm 10,951 schools from 44,655 given schools in Colombia from the UNICEF team.\n",
    "\n",
    "We generated **5452** tiles for a confirmed school class and **8,647** not-schools classes at zoom 17 (about 300m x 300m per tile), and **5,904** school tiles together with **9,092** not-school tile (151m x 151m per tile) to be used to fine-tune the xception model with Sat_Xception. A more detailed tiles breakdown is available at the following table.\n",
    "\n",
    "\n",
    "|Tasks|Confirmed | Unreconginized | not-schools| Total | Additional |\n",
    "| ----| -------- | -------------- | ---------- | ----- | ---------- |\n",
    "| Data Cleaning  |  6,663   | 11,774         | 2,268      | 20,705| 1st round |  \n",
    "| Data Cleaning  | 10,951   | 26,638         | 7,066      | 44,655| 2nd round w/ all data|\n",
    "| 1st round tile generation  | 5,452     | N/A     | 3,953 | 9,405| zoom 17 | \n",
    "| 2nd round tile generation  | 5,452     | N/A     |  8,647 | 14, 099 | zoom 17 |\n",
    "| 2nd round tile generation  | 5,904 | N/A     | 9,092 | 14,996 | zoom 18 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training dataset has been split into train and test **(80:20)**. Under each folder, we have two categories of image tiles that we care about, which are school and not-school. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We organize the training dataset in such a order:\n",
    "\n",
    "```\n",
    "\n",
    "└── main_model/\n",
    "    ├── train/\n",
    "           ├── not-school (3163 tiles)\n",
    "           ├── school (4362 tiles)\n",
    "    └── test/\n",
    "           ├── not-school (790 tiles + 300 tiles) \n",
    "           ├── school (1090 tiles)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Start transfer-learning, fine-tune with Sat-Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "Start time: 19/12 21:56:38\n",
      "\n",
      "Datasets used:\n",
      "'/example'\n",
      "\n",
      "Training details:\n",
      "{   'class_weight': {0: 2, 1: 1},\n",
      "    'early_stopping_min_delta': 0.01,\n",
      "    'early_stopping_patience': 5,\n",
      "    'img_size': (256, 256, 3),\n",
      "    'max_queue_size': 128,\n",
      "    'n_epo_phase1': [1, 2],\n",
      "    'n_epo_phase2': 15,\n",
      "    'n_rand_hp_iters': 5,\n",
      "    'n_total_hp_iters': 100,\n",
      "    'reduce_lr_min_delta': 0.1,\n",
      "    'reduce_lr_patience': 3,\n",
      "    'steps_per_test_epo': None,\n",
      "    'steps_per_train_epo': 256,\n",
      "    'use_multiprocessing': False,\n",
      "    'workers': 8}\n",
      "\n",
      "Model details:\n",
      "{   'dense_activation': ['relu', 'elu'],\n",
      "    'dense_size': [128, 256, 512],\n",
      "    'dropout_rate': [0, 0.1, 0.25, 0.5],\n",
      "    'freeze_cutoff': [0],\n",
      "    'loss': ['categorical_crossentropy'],\n",
      "    'lr_phase1': [0.0001, 0.001],\n",
      "    'lr_phase2': [1e-05, 0.0001],\n",
      "    'metrics': ['categorical_accuracy'],\n",
      "    'n_classes': 2,\n",
      "    'optimizer': [{'opt_func': 'adam'}, {'opt_func': 'rmsprop'}],\n",
      "    'output_activation': ['softmax'],\n",
      "    'weight_init': ['glorot_uniform']}\n",
      "\n",
      "\n",
      "========================================\n",
      "For training, found 3163 not_school images\n",
      "For training, found 4362 school images\n",
      "For testing, found 1090 not_school images\n",
      "For testing, found 1090 school images\n",
      "\n",
      "========================================\n",
      "Starting model at 1219_215638\n",
      "{   'class_weight': {0: 2, 1: 1},\n",
      "    'dense_activation': 'elu',\n",
      "    'dense_size': 128,\n",
      "    'dropout_rate': 0.25,\n",
      "    'freeze_cutoff': 0,\n",
      "    'loss': 'categorical_crossentropy',\n",
      "    'lr_phase1': 0.0004040589587718961,\n",
      "    'lr_phase2': 5.159119307041582e-05,\n",
      "    'max_queue_size': 128,\n",
      "    'n_classes': 2,\n",
      "    'n_epo_phase1': 2.0,\n",
      "    'n_epo_phase2': 15,\n",
      "    'optimizer': {'opt_func': 'rmsprop'},\n",
      "    'output_activation': 'softmax',\n",
      "    'steps_per_test_epo': 70.0,\n",
      "    'steps_per_train_epo': 256,\n",
      "    'use_multiprocessing': False,\n",
      "    'weight_init': 'glorot_uniform',\n",
      "    'workers': 8}\n",
      "2018-12-19 21:56:42.625181: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 1s 0us/step\n",
      "Phase 1, training near-output layer(s)\n",
      "Found 7525 images belonging to 2 classes.\n",
      "Epoch 1/2\n",
      "256/256 [==============================] - 615s 2s/step - loss: 0.8811 - categorical_accuracy: 0.6319\n",
      "Epoch 2/2\n",
      "256/256 [==============================] - 609s 2s/step - loss: 0.8122 - categorical_accuracy: 0.6645\n",
      "/nPhase 2, training from layer 0 on.\n",
      "Found 2180 images belonging to 2 classes.\n",
      "Found 7525 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "256/256 [==============================] - 2914s 11s/step - loss: 0.7549 - categorical_accuracy: 0.7070 - val_loss: 0.5691 - val_categorical_accuracy: 0.7071\n",
      "Epoch 2/15\n",
      " 41/256 [===>..........................] - ETA: 37:52 - loss: 0.7008 - categorical_accuracy: 0.7515"
     ]
    }
   ],
   "source": [
    "!sat_xception train -model=xception -train=train -valid=test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. An option to train and fine-tune the model with NVIDIA docker and GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. (optional) Run Sat_Xception notebook under NVIDIA docker on a cloud machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run a pre-built nvidia-docker image from us, you need to go through these few steps:\n",
    "\n",
    "- start an AWS Deep learning AMI EC2 machine with jupyter security group setup;\n",
    "\n",
    "- ssh to the GPU cloud machine;\n",
    "\n",
    "- install [docker](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/docker-basics.html) and [nvidia-docker](https://towardsdatascience.com/using-docker-to-set-up-a-deep-learning-environment-on-aws-6af37a78c551) on AWS EC2 GPU machine. I test this script on a g2.x8large machine. \n",
    "\n",
    "- copy the main_model to your GPU cloud computer;\n",
    "\n",
    "- Run `nvidia-docker run -v $PWD:/example -p 8888:8888 -it geoyi/sat_xception` under the directory `main_model`, this command will pull a pre-built docker image from dockerhub; and run a jupyter notebook server on port 8888. \n",
    "\n",
    "- At another terminal tab, run `ssh -i YOUR_AWS_KEY.pem -L 8888:localhost:8888 ubuntu@xxxxxxx` to allow you to access the jupyter notebook from outside; \n",
    "\n",
    "- When you run the notebook the first time, copy and pasted something like http://127.0.0.1::8888/?token=xxxxxx to your browser to open the notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. (optional) Run Sat_Xception under NVIDIA docker on a cloud machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- start an AWS Deep learning AMI EC2 machine with jupyter security group setup;\n",
    "\n",
    "- ssh to the GPU cloud machine;\n",
    "\n",
    "- install [docker](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/docker-basics.html) and [nvidia-docker](https://towardsdatascience.com/using-docker-to-set-up-a-deep-learning-environment-on-aws-6af37a78c551) on AWS EC2 GPU machine. I test this script on a g2.x8large machine. \n",
    "\n",
    "- copy the main_model to your GPU cloud computer;\n",
    "\n",
    "- Run `nvidia-docker run -v $PWD:/example -it geoyi/sat_xception bash` to start the docker container and run CLI;\n",
    "\n",
    "- `cd example`\n",
    "\n",
    "- run `pip install -e .` to install sat_xception package;\n",
    "\n",
    "- run `sat_xception train -model=xception -train=train -valid=test` to train school detection with a pre-trained xception model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sat-Xception is saving all the model checkpoint and the graph to Tensorboard, so you can monitor how the training performs along the training process. \n",
    "\n",
    "**We trained above model on an AWS GPU machine, `g2.x8large` specifically, for 40 hours, the model wasn't run on this notebook but at the backend on an AWS cloud machine.** Here are some results from Tensorboard. \n",
    "\n",
    "You can inspect the training tensorboard by running `tensorboard --logdir=tensorboard/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Training_accuracy](figures/training_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Validation_accuracy](figures/validation_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![learning rate and loss](figures/loss_lr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Roadmap for next iteration (for the first iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All computation and data manipulation was carried out on Amazon Web Services (AWS). We used AWS Elastic Compute Cloud (EC2) Deep Learning AMI for the model training. \n",
    "\n",
    "Through the 40+ hours of training and tuning, we observed the model accuracy is going up with the model loss goes down (see above images). It indicates the model is keeping learning new image features from the given tiles with image augmentation. Image augmentation was generated by the high-level deep learning python package Keras, which zoom in and out, vertically and horizontally flip, brighten, and shift the color channel of the given tiles. Therefore, it allows the model to see diverse features of the tiles that can reflect in real satellite imagery tiles. **In next iteration, we can include diverse classes in not-school classes to balance out the binary classes**.\n",
    "\n",
    "\n",
    "In the first iteration of the model, we used **categorical_crossentropy** and class weight to encourage the model to learn. **At the second iteration, we can try out a few other loss functions especially binary_crossentropy, which is designed to monitor binary classification**.\n",
    "\n",
    "\n",
    "Deep learning can be a bit tedious that we are using millions of parameter to tune. A good strategy is to test a wide range of hyperparameters and select the model with high performance. Our current best performance (see above Tensorboard result) is the last trained model that recorded on Dec 18 13:14:08. \n",
    "\n",
    "We can do A-B test between two built-in models, Xception and MobileNetV2, to see the model performance as well as model inference.\n",
    "\n",
    "For the first iteration of school detection, we adapted the hyperparameters from another project we've done for high-voltage tower detection. **All the default hyperparameters for training is written in `train_config.py` under Sat_Xception, which can be further tuned particularly for school detection purpose. We provide the following script to help the UNICEF team to tune and over-write current configure hyperparameters**. \n",
    "\n",
    " **For the second iteration we can give the model a long time to train and tune on the given binary class tiles with following hyperparameters optimizing and improvement**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** Any hyperparameters you set at following script, when you excute the cell, it will overwrite current default according hyperparameters in `Sat-Xception` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%file sat_xception/train_config.py\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "config.py\n",
    "\n",
    "List some configuration parameters for training model\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from os import path as op\n",
    "\n",
    "\n",
    "# Set directories for saving model weights and tensorboard information\n",
    "data_dir = os.getcwd()\n",
    "\n",
    "#     cloud_comp = False\n",
    "\n",
    "ckpt_dir = op.join(os.getcwd(), \"models\")\n",
    "tboard_dir = op.join(os.getcwd(), \"tensorboard\")\n",
    "preds_dir = op.join(os.getcwd(), \"preds\")\n",
    "plot_dir = op.join(os.getcwd(), \"plots\")\n",
    "cloud_comp = False\n",
    "\n",
    "if not op.isdir(ckpt_dir):\n",
    "    os.mkdir(ckpt_dir)\n",
    "if not op.isdir(tboard_dir):\n",
    "    os.mkdir(tboard_dir)\n",
    "\n",
    "model_params = dict(loss=['categorical_crossentropy'],\n",
    "                    optimizer=[dict(opt_func='adam'),\n",
    "                               dict(opt_func='rmsprop')],\n",
    "                               # SGD as below performed notably poorer in 1st big hyperopt run\n",
    "                               #dict(opt_func='sgd', momentum=hp.uniform('momentum', 0.5, 0.9))],\n",
    "                    lr_phase1=[1e-4, 1e-3],  # learning rate for phase 1 (output layer only)\n",
    "                    lr_phase2=[1e-5, 1e-4],  # learning rate for phase 2 (all layers beyond freeze_cutoff)\n",
    "                    weight_init=['glorot_uniform'],\n",
    "                    metrics=['categorical_accuracy'],\n",
    "                    # Blocks organized in 10s, 66, 76, 86, etc.\n",
    "                    freeze_cutoff=[0],  # Layer below which no training/updating occurs on weights\n",
    "                    dense_size=[128, 256, 512],  # Number of nodes in 2nd to final layer\n",
    "                    n_classes=2,  # Number of class choices in final layer\n",
    "                    output_activation=['softmax'],\n",
    "                    dense_activation=['relu', 'elu'],\n",
    "                    dropout_rate=[0, 0.1, 0.25, 0.5])  # Dropout in final layer\n",
    "\n",
    "train_params = dict(n_rand_hp_iters=5,\n",
    "                    n_total_hp_iters=100,  # Total number of HyperParam experiments to run\n",
    "                    n_epo_phase1=[1, 2],  # Number of epochs training only top layer\n",
    "                    n_epo_phase2=15,  # Number of epochs fine tuning whole model\n",
    "                    max_queue_size=128,\n",
    "                    workers=8,\n",
    "                    use_multiprocessing=False,\n",
    "                    #prop_total_img_set=0.5,  # Proportion of total images per train epoch\n",
    "                    img_size=(256, 256, 3),\n",
    "                    early_stopping_patience=5,  # Number of iters w/out val_acc increase\n",
    "                    early_stopping_min_delta=0.01,\n",
    "                    reduce_lr_patience=3,  # Number of iters w/out val_acc increase\n",
    "                    reduce_lr_min_delta=0.1,\n",
    "                    class_weight={0: 2, 1: 1},  # Based on pakistan_redux image counts\n",
    "                    steps_per_train_epo=256,\n",
    "                    steps_per_test_epo=None)\n",
    "\n",
    "# Define params for ImageDataGenerator and ImageDataGenerator.flow_from_directory\n",
    "data_flow = dict(image_data_generator=dict(horizontal_flip=True,\n",
    "                                           vertical_flip=True,\n",
    "                                           rotation_range=180,\n",
    "                                           zoom_range=(1, 1.2),\n",
    "                                           brightness_range=(0.8, 1.2),\n",
    "                                           channel_shift_range=10),\n",
    "                 flow_from_dir=dict(target_size=train_params['img_size'][:2],  # Only want width/height here\n",
    "                                    color_mode='rgb',\n",
    "                                    classes=['not_school', 'school'],  # Keep this ordering, it should match class_weights\n",
    "                                    batch_size=32,  # Want as large as GPU can handle, using batch-norm layers\n",
    "                                    seed=42,  # Seed for random number generator\n",
    "                                    save_to_dir=None))  # Set to visualize augmentations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Summary for the first iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For coming work we will focus on:\n",
    "\n",
    "    - cleaning training dataset especially get rid of the school tiles that have not-school info, and add more not-school tiles;\n",
    "    - update loss function and evaluation matrix accordingly; \n",
    "    - A-B test between Xception and MobileNetV2, visualizing and evaluating the model performance;\n",
    "    - packaging the best-performed model with Tensorflow serving as docker images;\n",
    "    - Write an explicit instruction on model inference with created docker images for school detections; \n",
    "    - Development Seed Data Team validate model prediction; \n",
    "    - Documentation and share updated scripts and documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The second iteration updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training datasets, in zoom 17 and zoom 18, both went to train Xception and MobileNetV2. Your concern around zoom 17 was proved to be correct. From monitoring the model training, we observed the model trained with Xception on zoom 18 performed better than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception with Zoom18 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensorboard-z18-accuracy.png](figures/tensorboard-z18-accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensorboard-val-accuracy-z18.png](figures/tensorboard-val-accuracy-z18.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensorboard-loss-zoom18.png](figures/tensorboard-loss-zoom18.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The curent accuracy approached 0.9 with Val accuracy to 0.88.**\n",
    "\n",
    "**The best-performed model now has been turned into [tensorflow-serving docker image](https://cloud.docker.com/u/geoyi/repository/docker/geoyi/unicef_school_tf_serving), which will allow us to make model inference over a large area like Colombia, 50.8 million zoom 18 tiles, more efficient. Currently, we estimate it will take a day to run the model through Colombia with our current ML inference pipeline**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ROC-school.png](figures/ROC-school.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are currently using our tensorflow serving image testing out the trained model's predicting power over a northwest part of Colombia before we have our Data Team, five expert mappers, to validate the model results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
